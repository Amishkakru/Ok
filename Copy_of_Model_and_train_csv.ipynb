{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amishkakru/Ok/blob/main/Copy_of_Model_and_train_csv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M_hIl_-C6P8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bae77f5d-7ba2-4327-eb76-716d64b37b39"
      },
      "source": [
        "#before running this please change the RUNTIME to GPU (Runtime -> Change runtime type -> set harware accelarotor as GPU)\n",
        "#Mount our google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mneMgm9j7ack"
      },
      "source": [
        "[link text](https://)Note : Use the drive link for the processed dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the zip file\n",
        "zip_file_path = '/content/drive/MyDrive/data.zip'  # Adjust the path if needed\n",
        "\n",
        "# Directory to extract the contents\n",
        "extracted_folder = '/content/drive/MyDrive/extracted_data'  # Adjust the path if needed\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(extracted_folder, exist_ok=True)\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder)\n",
        "\n",
        "# List the files in the extracted folder\n",
        "extracted_files = os.listdir(extracted_folder)\n",
        "print(f\"Contents of {zip_file_path} have been extracted to {extracted_folder}.\")\n",
        "\n",
        "# Display the extracted files\n",
        "print(\"Extracted files:\")\n",
        "for file_name in extracted_files:\n",
        "    print(file_name)"
      ],
      "metadata": {
        "id": "HPsOFQQQ7xen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hlPaQS4e5VI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "66963fc7-271e-489d-f05d-ef9ed8bf03d4"
      },
      "source": [
        "!pip3 install face_recognition\n",
        "!pip install --upgrade dlib"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=244edb1aabf2e2af7eedae15d8c1caf3c199c00ebd21763ca9d59cf00d6d0b0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (19.24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Video** **Preprocessing**"
      ],
      "metadata": {
        "id": "BQmeUhsW-Ylm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ22Sj8d0JoT"
      },
      "source": [
        "#THis code is to check if the video is corrupted or not..\n",
        "#If the video is corrupted delete the video.\n",
        "import glob\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import face_recognition\n",
        "#Check if the file is corrupted or not\n",
        "def validate_video(vid_path,train_transforms):\n",
        "      transform = train_transforms\n",
        "      count = 20\n",
        "      video_path = vid_path\n",
        "      frames = []\n",
        "      a = int(100/count)\n",
        "      first_frame = np.random.randint(0,a)\n",
        "      temp_video = video_path.split('/')[-1]\n",
        "      for i,frame in enumerate(frame_extract(video_path)):\n",
        "        frames.append(transform(frame))\n",
        "        if(len(frames) == count):\n",
        "          break\n",
        "      frames = torch.stack(frames)\n",
        "      frames = frames[:count]\n",
        "      return frames\n",
        "#extract a from from video\n",
        "def frame_extract(path):\n",
        "  vidObj = cv2.VideoCapture(path)\n",
        "  success = 1\n",
        "  while success:\n",
        "      success, image = vidObj.read()\n",
        "      if success:\n",
        "          yield image\n",
        "\n",
        "im_size = 112\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                                        transforms.ToPILImage(),\n",
        "                                        transforms.Resize((im_size,im_size)),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean,std)])\n",
        "\n",
        "video_fil =  glob.glob('/content/drive/MyDrive/extracted_data/deep-fake-dataset/Celeb-Youtube-fake/*.mp4')\n",
        "video_fil += glob.glob('/content/drive/MyDrive/extracted_data/deep-fake-dataset/Celeb-real/*.mp4')\n",
        "video_fil += glob.glob('/content/drive/MyDrive/extracted_data/deep-fake-dataset/YouTube-real/*.mp4')\n",
        "\n",
        "\n",
        "print(\"Total no of videos :\" , len(video_fil))\n",
        "\n",
        "count = 0;\n",
        "for i in video_fil:\n",
        "  try:\n",
        "    count+=1\n",
        "    validate_video(i,train_transforms)\n",
        "    print(count)\n",
        "  except:\n",
        "    print(\"Number of video processed: \" , count ,\" Remaining : \" , (len(video_fil) - count))\n",
        "    print(\"Corrupted video is : \" , i)\n",
        "    continue\n",
        "print((len(video_fil) - count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## run again"
      ],
      "metadata": {
        "id": "LheQm_HkTs2F"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEIygy8uDFXc"
      },
      "source": [
        "#to load preprocessod video to memory\n",
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import copy\n",
        "import random\n",
        "\n",
        "video_files =  glob.glob('/content/drive/MyDrive/extracted_data/deep-fake-dataset/Celeb-Youtube-fake/*.mp4')\n",
        "video_files += glob.glob('/content/drive/MyDrive/extracted_data/deep-fake-dataset/Celeb-real/*.mp4')\n",
        "video_files += glob.glob('/content/drive/MyDrive/extracted_data/deep-fake-dataset/YouTube-real/*.mp4')\n",
        "\n",
        "\n",
        "random.shuffle(video_files)\n",
        "random.shuffle(video_files)\n",
        "frame_count = []\n",
        "count = 0\n",
        "for video_file in video_files:\n",
        "  cap = cv2.VideoCapture(video_file)\n",
        "  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<100):\n",
        "    video_files.remove(video_file)\n",
        "    continue\n",
        "  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "  count = count+1\n",
        "  print(count)\n",
        "print(\"frames are \" , frame_count)\n",
        "print(\"Total no of video: \" , len(frame_count))\n",
        "print('Average frame per video:',np.mean(frame_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqGXNkqhDKZU"
      },
      "source": [
        "# load the video name and labels from csv\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import face_recognition\n",
        "class video_dataset(Dataset):\n",
        "    def __init__(self,video_names,labels,sequence_length = 60,transform = None):\n",
        "        self.video_names = video_names\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.count = sequence_length\n",
        "    def __len__(self):\n",
        "        return len(self.video_names)\n",
        "    def __getitem__(self,idx):\n",
        "        video_path = self.video_names[idx]\n",
        "        frames = []\n",
        "        a = int(100/self.count)\n",
        "        first_frame = np.random.randint(0,a)\n",
        "        temp_video = video_path.split('/')[-1]\n",
        "        #print(temp_video)\n",
        "        label = self.labels.iloc[(labels.loc[labels[\"file\"] == temp_video].index.values[0]),1]\n",
        "        if(label == 0):\n",
        "          label = 0\n",
        "        if(label == 1):\n",
        "          label = 1\n",
        "        for i,frame in enumerate(self.frame_extract(video_path)):\n",
        "          frames.append(self.transform(frame))\n",
        "          if(len(frames) == self.count):\n",
        "            break\n",
        "        frames = torch.stack(frames)\n",
        "        frames = frames[:self.count]\n",
        "        #print(\"length:\" , len(frames), \"label\",label)\n",
        "        return frames,label\n",
        "    def frame_extract(self,path):\n",
        "      vidObj = cv2.VideoCapture(path)\n",
        "      success = 1\n",
        "      while success:\n",
        "          success, image = vidObj.read()\n",
        "          if success:\n",
        "              yield image\n",
        "\n",
        "#plot the image\n",
        "def im_plot(tensor):\n",
        "    image = tensor.cpu().numpy().transpose(1,2,0)\n",
        "    b,g,r = cv2.split(image)\n",
        "    image = cv2.merge((r,g,b))\n",
        "    image = image*[0.22803, 0.22145, 0.216989] +  [0.43216, 0.394666, 0.37645]\n",
        "    image = image*255.0\n",
        "    plt.imshow(image.astype(int))\n",
        "    plt.show()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1leMozhXa5LF"
      },
      "source": [
        "#count the number of fake and real videos\n",
        "def number_of_real_and_fake_videos(data_list):\n",
        "  header_list = [\"file\",\"label\"]\n",
        "  lab = pd.read_csv('/content/drive/My Drive/Global_metadata.csv',names=header_list)\n",
        "  fake = 0\n",
        "  real = 0\n",
        "  lab.head()\n",
        "  for i in data_list:\n",
        "    temp_video = i.split('/')[-1]\n",
        "    label = lab.iloc[(labels.loc[labels[\"file\"] == temp_video].index.values[0]),1]\n",
        "    #print(label)\n",
        "    if(label == '0'):\n",
        "      fake+=1\n",
        "    if(label == '1'):\n",
        "      real+=1\n",
        "  return real,fake"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWMZn0YHDO2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "outputId": "ba8e5fcb-984a-4579-c079-c4dfac90168c"
      },
      "source": [
        "# load the labels and video in data loader\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "header_list = [\"file\",\"label\"]\n",
        "labels = pd.read_csv('/content/drive/My Drive/Global_metadata.csv',names=header_list)\n",
        "#print(labels)\n",
        "train_videos = video_files[:int(0.8*len(video_files))]\n",
        "valid_videos = video_files[int(0.8*len(video_files)):]\n",
        "print(\"train : \" , len(train_videos))\n",
        "print(\"test : \" , len(valid_videos))\n",
        "#train_videos,valid_videos = train_test_split(data,test_size = 0.2)\n",
        "# print(train_videos)\n",
        "\n",
        "print(\"TRAIN: \", \"Real:\",number_of_real_and_fake_videos(train_videos)[0],\" Fake:\",number_of_real_and_fake_videos(train_videos)[1])\n",
        "print(\"TEST: \", \"Real:\",number_of_real_and_fake_videos(valid_videos)[0],\" Fake:\",number_of_real_and_fake_videos(valid_videos)[1])\n",
        "\n",
        "\n",
        "im_size = 112\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                                        transforms.ToPILImage(),\n",
        "                                        transforms.Resize((im_size,im_size)),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean,std)])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                                        transforms.ToPILImage(),\n",
        "                                        transforms.Resize((im_size,im_size)),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean,std)])\n",
        "train_data = video_dataset(train_videos,labels,sequence_length = 10,transform = train_transforms)\n",
        "#print(train_data)\n",
        "val_data = video_dataset(valid_videos,labels,sequence_length = 10,transform = train_transforms)\n",
        "train_loader = DataLoader(train_data,batch_size = 4,shuffle = True,num_workers = 4)\n",
        "valid_loader = DataLoader(val_data,batch_size = 4,shuffle = True,num_workers = 4)\n",
        "image,label = train_data[0]\n",
        "im_plot(image[0,:,:,:])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train :  4808\n",
            "test :  1202\n",
            "TRAIN:  Real: 959  Fake: 3849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST:  Real: 234  Fake: 968\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtOXSqyBDRnD"
      },
      "source": [
        "#Model with feature visualization\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, num_classes,latent_dim= 2048, lstm_layers=1 , hidden_dim = 2048, bidirectional = False):\n",
        "        super(Model, self).__init__()\n",
        "        model = models.resnext50_32x4d(pretrained = True) #Residual Network CNN\n",
        "        self.model = nn.Sequential(*list(model.children())[:-2])\n",
        "        self.lstm = nn.LSTM(latent_dim,hidden_dim, lstm_layers,  bidirectional)\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.dp = nn.Dropout(0.4)\n",
        "        self.linear1 = nn.Linear(2048,num_classes)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "    def forward(self, x):\n",
        "        batch_size,seq_length, c, h, w = x.shape\n",
        "        x = x.view(batch_size * seq_length, c, h, w)\n",
        "        fmap = self.model(x)\n",
        "        x = self.avgpool(fmap)\n",
        "        x = x.view(batch_size,seq_length,2048)\n",
        "        x_lstm,_ = self.lstm(x,None)\n",
        "        return fmap,self.dp(self.linear1(torch.mean(x_lstm,dim = 1)))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYNhn10tDV90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "80dfe86c-7238-489b-ed6e-fd84da1bb7f5"
      },
      "source": [
        "model = Model(2).cuda()\n",
        "a,b = model(torch.from_numpy(np.empty((1,20,3,112,112))).type(torch.cuda.FloatTensor))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n",
            "100%|██████████| 95.8M/95.8M [00:00<00:00, 157MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKheLUWBDaNN"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def train_epoch(epoch, num_epochs, data_loader, model, criterion, optimizer):\n",
        "    model.train()\n",
        "    losses = AverageMeter()\n",
        "    accuracies = AverageMeter()\n",
        "\n",
        "    for i, (inputs, targets) in enumerate(data_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            targets = targets.cuda().type(torch.cuda.LongTensor)\n",
        "            inputs = inputs.cuda()\n",
        "\n",
        "        _, outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets.type(torch.cuda.LongTensor))\n",
        "        acc = calculate_accuracy(outputs, targets.type(torch.cuda.LongTensor))\n",
        "        losses.update(loss.item(), inputs.size(0))\n",
        "        accuracies.update(acc, inputs.size(0))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(\n",
        "            \"\\r[Epoch %d/%d] [Batch %d/%d] [Loss: %f, Acc: %.2f%%]\" %\n",
        "            (epoch, num_epochs, i, len(data_loader), losses.avg, accuracies.avg)\n",
        "        )\n",
        "\n",
        "    torch.save(model.state_dict(), '/content/checkpoint.pt')\n",
        "    return [losses.avg, accuracies.avg]\n",
        "\n",
        "def test(epoch, model, data_loader, criterion):\n",
        "    print('Testing')\n",
        "    model.eval()\n",
        "    losses = AverageMeter()\n",
        "    accuracies = AverageMeter()\n",
        "    pred = []\n",
        "    true = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, targets) in enumerate(data_loader):\n",
        "            if torch.cuda.is_available():\n",
        "                targets = targets.cuda().type(torch.cuda.FloatTensor)\n",
        "                inputs = inputs.cuda()\n",
        "\n",
        "            _, outputs = model(inputs)\n",
        "            loss = torch.mean(criterion(outputs, targets.type(torch.cuda.LongTensor)))\n",
        "            acc = calculate_accuracy(outputs, targets.type(torch.cuda.LongTensor))\n",
        "\n",
        "            _, p = torch.max(outputs, 1)\n",
        "            true += (targets.type(torch.cuda.LongTensor)).detach().cpu().numpy().reshape(len(targets)).tolist()\n",
        "            pred += p.detach().cpu().numpy().reshape(len(p)).tolist()\n",
        "\n",
        "            print(\n",
        "                \"\\r[Batch %d/%d]  [Loss: %f, Acc: %.2f%%]\" %\n",
        "                (i, len(data_loader), losses.avg, accuracies.avg)\n",
        "            )\n",
        "\n",
        "        print('\\nAccuracy {}'.format(accuracies.avg))\n",
        "\n",
        "    torch.save(model.state_dict(), '/content/drive/MyDrive/model.pt')\n",
        "    return true, pred, losses.avg, accuracies.avg\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def calculate_accuracy(outputs, targets):\n",
        "    batch_size = targets.size(0)\n",
        "\n",
        "    _, pred = outputs.topk(1, 1, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(targets.view(1, -1))\n",
        "    n_correct_elems = correct.float().sum().item()\n",
        "    return 100 * n_correct_elems / batch_size\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8WneBZNfysN"
      },
      "source": [
        "import seaborn as sn\n",
        "#Output confusion matrix\n",
        "def print_confusion_matrix(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print('True positive = ', cm[0][0])\n",
        "    print('False positive = ', cm[0][1])\n",
        "    print('False negative = ', cm[1][0])\n",
        "    print('True negative = ', cm[1][1])\n",
        "    print('\\n')\n",
        "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
        "    sn.set(font_scale=1.4) # for label size\n",
        "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
        "    plt.ylabel('Actual label', size = 20)\n",
        "    plt.xlabel('Predicted label', size = 20)\n",
        "    plt.xticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
        "    plt.yticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
        "    plt.ylim([2, 0])\n",
        "    plt.show()\n",
        "    calculated_acc = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+ cm[1][1])\n",
        "    print(\"Calculated Accuracy\",calculated_acc*100)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fExJLjt2AtV9"
      },
      "source": [
        "def plot_loss(train_loss_avg,test_loss_avg,num_epochs):\n",
        "  loss_train = train_loss_avg\n",
        "  loss_val = test_loss_avg\n",
        "  print(num_epochs)\n",
        "  epochs = range(1,num_epochs+1)\n",
        "  plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "  plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "  plt.title('Training and Validation loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "def plot_accuracy(train_accuracy,test_accuracy,num_epochs):\n",
        "  loss_train = train_accuracy\n",
        "  loss_val = test_accuracy\n",
        "  epochs = range(1,num_epochs+1)\n",
        "  plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
        "  plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
        "  plt.title('Training and Validation accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUe1XrYnDdit",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "fc7ba634-8a94-413b-a438-17a68eebb2da"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#learning rate\n",
        "lr = 1e-5#0.001\n",
        "#number of epochs\n",
        "num_epochs = 20\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= lr,weight_decay = 1e-5)\n",
        "\n",
        "#class_weights = torch.from_numpy(np.asarray([1,15])).type(torch.FloatTensor).cuda()\n",
        "#criterion = nn.CrossEntropyLoss(weight = class_weights).cuda()\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "train_loss_avg =[]\n",
        "train_accuracy = []\n",
        "test_loss_avg = []\n",
        "test_accuracy = []\n",
        "for epoch in range(1,num_epochs+1):\n",
        "    temp= train_epoch(epoch,num_epochs,train_loader,model,criterion,optimizer)\n",
        "    l=temp[0]\n",
        "    acc=temp[1]\n",
        "    train_loss_avg.append(l)\n",
        "    train_accuracy.append(acc)\n",
        "    true,pred,tl,t_acc = test(epoch,model,valid_loader,criterion)\n",
        "    test_loss_avg.append(tl)\n",
        "    test_accuracy.append(t_acc)\n",
        "plot_loss(train_loss_avg,test_loss_avg,len(train_loss_avg))\n",
        "plot_accuracy(train_accuracy,test_accuracy,len(train_accuracy))\n",
        "print(confusion_matrix(true,pred))\n",
        "print_confusion_matrix(true,pred)\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'cuda'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-e4e4998017a0>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-7add59a3ba9a>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(epoch, num_epochs, data_loader, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'cuda'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = confusion_matrix\n",
        "Precision =( matrix[1][0])/(matrix[0][1] + matrix[1][1])\n",
        "Recall = (matrix[0][0])/(matrix[0][1] + matrix[1][1])\n",
        "F1 = 2 * (Precision * Recall)/(Precision + Recall)"
      ],
      "metadata": {
        "id": "VEzQZbyUxJpV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}